version: "2"
services:
  hadoop_namenode:
    image: apache/hadoop:3
    hostname: namenode
    container_name: namenode
    command: ["hdfs", "namenode"]
    ports:
      - 9870:9870
    env_file:
      - ./config
    environment:
        ENSURE_NAMENODE_DIR: "/tmp/hadoop-root/dfs/name"
  hadoop_datanode:
    image: apache/hadoop:3
    container_name: datanode
    command: ["hdfs", "datanode"]
    env_file:
      - ./config      
  hadoop_resourcemanager:
    image: apache/hadoop:3
    hostname: resourcemanager
    command: ["yarn", "resourcemanager"]
    ports:
        - 8088:8088
    env_file:
      - ./config
    volumes:
      - ./test.sh:/opt/test.sh
  hadoop_nodemanager:
    image: apache/hadoop:3
    command: ["yarn", "nodemanager"]
    env_file:
      - ./config

  spark-master:
      image: bde2020/spark-master:3.0.0-hadoop3.2
      container_name: spark-master
      depends_on:
        - namenode
        - datanode
      ports:
        - "8080:8080"
        - "7077:7077"
      environment:
        - INIT_DAEMON_STEP=setup_spark
        - CORE_CONF_fs_defaultFS=hdfs://namenode:9000
  spark-worker-1:
    image: bde2020/spark-worker:3.0.0-hadoop3.2
    container_name: spark-worker-1
    depends_on:
      - spark-master
    ports:
      - "8081:8081"
    environment:
      - "SPARK_MASTER=spark://spark-master:7077"
      - CORE_CONF_fs_defaultFS=hdfs://namenode:9000